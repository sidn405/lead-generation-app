#!/usr/bin/env python3
"""
Multilingual DM Generation System
Integrates with your existing dm_sequences.py and persona system
"""

import re
import random
from typing import Dict, List, Optional, Tuple

# Language detection keywords and patterns
LANGUAGE_KEYWORDS = {
    "english": {
        "keywords": ["the", "and", "is", "in", "to", "of", "it", "you", "that", "he", "was", "for", "on", "are", "as", "with", "his", "they", "at"],
        "greetings": ["Hi", "Hello", "Hey", "Greetings"],
        "connectors": ["I love", "I'm interested in", "I think it's great", "I'd love to"],
        "closings": ["Let's connect!", "Let's chat!", "Best regards!", "Talk soon!"]
    },
        "spanish": {
        "keywords": ["que", "con", "para", "por", "una", "como", "muy", "todo", "m√°s", "hacer", "tiempo", "trabajo", "vida", "amor", "familia"],
        "greetings": ["¬°Hola", "Hola", "¬°Hey", "Saludos"],
        "connectors": ["Me encanta", "Me gusta", "Estoy interesado en", "Ser√≠a genial"],
        "closings": ["¬°Conectemos!", "¬°Hablemos!", "¬°Saludos!", "¬°Hasta pronto!"]
    },
    "french": {
        "keywords": ["que", "avec", "pour", "dans", "une", "comme", "tr√®s", "tout", "plus", "faire", "temps", "travail", "vie", "amour"],
        "greetings": ["Salut", "Bonjour", "Hey", "Coucou"],
        "connectors": ["J'adore", "J'aime", "Je suis int√©ress√© par", "Ce serait g√©nial"],
        "closings": ["Connectons-nous!", "Parlons!", "√Ä bient√¥t!", "Salutations!"]
    },
    "german": {
        "keywords": ["und", "mit", "f√ºr", "auf", "eine", "wie", "sehr", "alle", "mehr", "machen", "zeit", "arbeit", "leben", "liebe"],
        "greetings": ["Hallo", "Hi", "Hey", "Gr√º√ü dich"],
        "connectors": ["Ich liebe", "Mir gef√§llt", "Ich interessiere mich f√ºr", "Das w√§re toll"],
        "closings": ["Lass uns connecten!", "Lass uns sprechen!", "Bis bald!", "Gr√º√üe!"]
    },
    "portuguese": {
        "keywords": ["que", "com", "para", "por", "uma", "como", "muito", "todo", "mais", "fazer", "tempo", "trabalho", "vida", "amor"],
        "greetings": ["Oi", "Ol√°", "E a√≠", "Opa"],
        "connectors": ["Eu amo", "Eu gosto", "Estou interessado em", "Seria √≥timo"],
        "closings": ["Vamos nos conectar!", "Vamos conversar!", "At√© logo!", "Abra√ßos!"]
    },
    "italian": {
        "keywords": ["che", "con", "per", "una", "come", "molto", "tutto", "pi√π", "fare", "tempo", "lavoro", "vita", "amore"],
        "greetings": ["Ciao", "Salve", "Ehi", "Buongiorno"],
        "connectors": ["Amo", "Mi piace", "Sono interessato a", "Sarebbe fantastico"],
        "closings": ["Connettiamoci!", "Parliamo!", "A presto!", "Saluti!"]
    },
    "japanese": {
        "keywords": ["„Åß„Åô", "„Åæ„Åô", "„Åì„Å®", "„ÇÇ„ÅÆ", "„Åü„ÇÅ", "„Å´„Å§„ÅÑ„Å¶", "„Åã„Çâ", "„Åæ„Åß", "„Å®„ÅÑ„ÅÜ", "„Å®„Åó„Å¶"],
        "greetings": ["„Åì„Çì„Å´„Å°„ÅØ", "„ÅØ„Åò„ÇÅ„Åæ„Åó„Å¶", "„ÅäÁñ≤„ÇåÊßò", "„Çà„Çç„Åó„Åè"],
        "connectors": ["Â§ßÂ•Ω„Åç„Åß„Åô", "ËààÂë≥„Åå„ÅÇ„Çä„Åæ„Åô", "Á¥†Êô¥„Çâ„Åó„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô", "„Åú„Å≤"],
        "closings": ["„Å§„Å™„Åå„Çä„Åæ„Åó„Çá„ÅÜÔºÅ", "„ÅäË©±„Åó„Åó„Åæ„Åó„Çá„ÅÜÔºÅ", "„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„Åó„Åæ„ÅôÔºÅ", "„Åæ„Åü‰ªäÂ∫¶ÔºÅ"]
    },
    "korean": {
        "keywords": ["Ïù¥", "Í∞Ä", "ÏùÑ", "Î•º", "Ïóê", "ÏóêÏÑú", "ÏôÄ", "Í≥º", "Î°ú", "ÏúºÎ°ú", "Ïùò", "ÎèÑ", "Îßå", "Î∂ÄÌÑ∞"],
        "greetings": ["ÏïàÎÖïÌïòÏÑ∏Ïöî", "ÏïàÎÖï", "Î∞òÍ∞ëÏäµÎãàÎã§", "Ï≤òÏùå ÎµôÍ≤†ÏäµÎãàÎã§"],
        "connectors": ["Ï¢ãÏïÑÌï©ÎãàÎã§", "Í¥ÄÏã¨Ïù¥ ÏûàÏäµÎãàÎã§", "ÌõåÎ•≠ÌïòÎã§Í≥† ÏÉùÍ∞ÅÌï©ÎãàÎã§", "Íº≠"],
        "closings": ["Ïó∞Í≤∞Ìï¥Ïöî!", "ÎåÄÌôîÌï¥Ïöî!", "Í∞êÏÇ¨Ìï©ÎãàÎã§!", "Îòê ÎßåÎÇòÏöî!"]
    },
    "chinese": {
        "keywords": ["ÁöÑ", "‰∫Ü", "Âú®", "ÊòØ", "Êàë", "Êúâ", "Âíå", "Â∞±", "‰∏ç", "‰∫∫", "ÈÉΩ", "‰∏Ä", "‰∏™", "‰ºö", "ËØ¥"],
        "greetings": ["‰Ω†Â•Ω", "ÊÇ®Â•Ω", "Âó®", "Â§ßÂÆ∂Â•Ω"],
        "connectors": ["ÊàëÂñúÊ¨¢", "ÊàëÂØπ...ÊÑüÂÖ¥Ë∂£", "ÊàëËßâÂæóÂæàÊ£í", "ÂæàÊÉ≥"],
        "closings": ["ËÆ©Êàë‰ª¨ËøûÊé•ÂêßÔºÅ", "ËÆ©Êàë‰ª¨ËÅäËÅäÔºÅ", "ÊúüÂæÖ‰∫§ÊµÅÔºÅ", "ÂÜçËßÅÔºÅ"]
    },
    "arabic": {
        "keywords": ["ŸÅŸä", "ŸÖŸÜ", "ÿ•ŸÑŸâ", "ÿπŸÑŸâ", "ŸÖÿπ", "ÿπŸÜ", "ÿ£ŸÜ", "ŸÉŸÑ", "Ÿáÿ∞ÿß", "Ÿáÿ∞Ÿá", "ÿßŸÑÿ™Ÿä", "ÿßŸÑÿ∞Ÿä", "ŸÑŸÉŸÜ", "ÿ£Ÿà"],
        "greetings": ["ŸÖÿ±ÿ≠ÿ®ÿß", "ÿ£ŸáŸÑÿß", "ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ", "ÿ£ŸáŸÑÿß Ÿàÿ≥ŸáŸÑÿß"],
        "connectors": ["ÿ£ÿ≠ÿ®", "ÿ£Ÿáÿ™ŸÖ ÿ®ŸÄ", "ÿ£ÿπÿ™ŸÇÿØ ÿ£ŸÜŸá ÿ±ÿßÿ¶ÿπ", "ÿ£ŸàÿØ"],
        "closings": ["ŸÑŸÜÿ™ŸàÿßÿµŸÑ!", "ŸÑŸÜÿ™ÿ≠ÿØÿ´!", "ŸÖÿπ ÿßŸÑÿ™ÿ≠Ÿäÿ©!", "ÿ•ŸÑŸâ ÿßŸÑŸÑŸÇÿßÿ°!"]
    },
    "hindi": {
        "keywords": ["‡§ï‡§æ", "‡§ï‡•á", "‡§ï‡•Ä", "‡§Æ‡•á‡§Ç", "‡§∏‡•á", "‡§ï‡•ã", "‡§™‡§∞", "‡§î‡§∞", "‡§π‡•à", "‡§π‡•à‡§Ç", "‡§•‡§æ", "‡§•‡•Ä", "‡§π‡•ã‡§ó‡§æ", "‡§π‡•ã‡§ó‡•Ä"],
        "greetings": ["‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "‡§π‡•à‡§≤‡•ã", "‡§π‡§æ‡§Ø", "‡§Ü‡§¶‡§æ‡§¨"],
        "connectors": ["‡§Æ‡•Å‡§ù‡•á ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à", "‡§Æ‡•à‡§Ç ‡§∞‡•Å‡§ö‡§ø ‡§∞‡§ñ‡§§‡§æ ‡§π‡•Ç‡§Ç", "‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à", "‡§Æ‡•à‡§Ç ‡§ö‡§æ‡§π‡•Ç‡§Ç‡§ó‡§æ"],
        "closings": ["‡§Ü‡§á‡§è ‡§ú‡•Å‡§°‡§º‡§§‡•á ‡§π‡•à‡§Ç!", "‡§Ü‡§á‡§è ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç!", "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", "‡§´‡§ø‡§∞ ‡§Æ‡§ø‡§≤‡§§‡•á ‡§π‡•à‡§Ç!"]
    },
    "russian": {
        "keywords": ["–≤", "–Ω–∞", "—Å", "–ø–æ", "–¥–ª—è", "–æ—Ç", "–¥–æ", "–∏–∑", "–∫", "—É", "–æ", "–ø—Ä–∏", "–∑–∞", "–ø–æ–¥"],
        "greetings": ["–ü—Ä–∏–≤–µ—Ç", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–•–∞–π", "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é"],
        "connectors": ["–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è", "–ú–µ–Ω—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç", "–Ø –¥—É–º–∞—é, —ç—Ç–æ –æ—Ç–ª–∏—á–Ω–æ", "–•–æ—Ç–µ–ª–æ—Å—å –±—ã"],
        "closings": ["–î–∞–≤–∞–π—Ç–µ –ø–æ–¥–∫–ª—é—á–∏–º—Å—è!", "–î–∞–≤–∞–π—Ç–µ –ø–æ–≥–æ–≤–æ—Ä–∏–º!", "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!", "–£–¥–∞—á–∏!"]
    }
}

# Platform-specific cultural adaptations by language
PLATFORM_LANGUAGE_STYLES = {
    "tiktok": {
        "spanish": {"style": "muy casual", "emojis": "üî•‚ú®üí´üöÄ", "tone": "juvenil y divertido"},
        "french": {"style": "d√©contract√©", "emojis": "üî•‚ú®üí´üöÄ", "tone": "jeune et amusant"},
        "german": {"style": "locker", "emojis": "üî•‚ú®üí´üöÄ", "tone": "jung und spa√üig"},
        "portuguese": {"style": "bem casual", "emojis": "üî•‚ú®üí´üöÄ", "tone": "jovem e divertido"},
        "japanese": {"style": "„Ç´„Ç∏„É•„Ç¢„É´", "emojis": "üî•‚ú®üí´üöÄ", "tone": "Ëã•„ÄÖ„Åó„Åè„Å¶Ê•Ω„Åó„ÅÑ"},
        "korean": {"style": "Ï∫êÏ£ºÏñº", "emojis": "üî•‚ú®üí´üöÄ", "tone": "Ï†äÍ≥† Ïû¨ÎØ∏ÏûàÎäî"},
        "chinese": {"style": "ÂæàÈöèÊÑè", "emojis": "üî•‚ú®üí´üöÄ", "tone": "Âπ¥ËΩªÊúâË∂£"},
        "english": {"style": "ultra-casual", "emojis": "üî•‚ú®üí´üöÄ", "tone": "young and fun"}
    },
    "linkedin": {
        "spanish": {"style": "profesional", "emojis": "", "tone": "respetuoso y profesional"},
        "french": {"style": "professionnel", "emojis": "", "tone": "respectueux et professionnel"},
        "german": {"style": "professionell", "emojis": "", "tone": "respektvoll und professionell"},
        "portuguese": {"style": "profissional", "emojis": "", "tone": "respeitoso e profissional"},
        "japanese": {"style": "„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´", "emojis": "", "tone": "Êï¨Ë™û„Åß‰∏ÅÂØß"},
        "korean": {"style": "Ï†ÑÎ¨∏Ï†Å", "emojis": "", "tone": "Ï†ïÏ§ëÌïòÍ≥† Ï†ÑÎ¨∏Ï†Å"},
        "chinese": {"style": "‰∏ì‰∏ö", "emojis": "", "tone": "Â∞äÈáçÂíå‰∏ì‰∏ö"},
        "english": {"style": "professional", "emojis": "", "tone": "respectful and professional"}
    }
}

def detect_language_from_bio(bio: str) -> str:
    """Detect language from bio text using keyword matching"""
    if not bio:
        return "english"
    
    bio_lower = bio.lower()
    language_scores = {}
    
    # Score each language based on keyword matches
    for language, data in LANGUAGE_KEYWORDS.items():
        score = 0
        for keyword in data["keywords"]:
            if keyword in bio_lower:
                score += 1
        
        if score > 0:
            language_scores[language] = score
    
    # Return language with highest score, or English as default
    if language_scores:
        detected = max(language_scores, key=language_scores.get)
        print(f"üåç Detected language: {detected} (score: {language_scores[detected]})")
        return detected
    
    return "english"

def detect_language_from_name(name: str) -> str:
    """Detect language from name patterns (basic heuristics)"""
    if not name:
        return "english"
    
    name_lower = name.lower()
    
    # Simple pattern matching for names
    patterns = {
        "spanish": ["jos√©", "mar√≠a", "carlos", "ana", "luis", "carmen", "antonio", "francisco"],
        "french": ["pierre", "marie", "jean", "claire", "michel", "sophie", "laurent", "isabelle"],
        "german": ["hans", "anna", "klaus", "petra", "wolfgang", "sabine", "michael", "andrea"],
        "portuguese": ["jo√£o", "ana", "carlos", "maria", "pedro", "claudia", "ricardo", "patricia"],
        "italian": ["marco", "giulia", "alessandro", "francesca", "andrea", "elena", "matteo", "chiara"],
        "japanese": ["takeshi", "yuki", "hiroshi", "akiko", "kenji", "mari", "satoshi", "emi"],
        "korean": ["kim", "park", "lee", "jung", "choi", "yoon", "jang", "lim"],
        "chinese": ["wang", "li", "zhang", "liu", "chen", "yang", "huang", "zhao"],
        "arabic": ["ahmed", "fatima", "mohamed", "aisha", "ali", "khadija", "omar", "zainab"],
        "russian": ["ivan", "anna", "dmitri", "elena", "sergei", "maria", "alexander", "olga"]
    }
    
    for language, name_patterns in patterns.items():
        for pattern in name_patterns:
            if pattern in name_lower:
                return language
    
    return "english"

def get_multilingual_prompt_modifier(platform: str, language: str, persona: str) -> str:
    """Get language and platform-specific prompt instructions for OpenAI"""
    
    # Base language instructions
    language_instructions = {
        "spanish": f"Responde en espa√±ol. Usa un tono {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('spanish', {}).get('tone', 'amigable')}.",
        "french": f"R√©ponds en fran√ßais. Utilise un ton {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('french', {}).get('tone', 'amical')}.",
        "german": f"Antworte auf Deutsch. Verwende einen {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('german', {}).get('tone', 'freundlichen')} Ton.",
        "portuguese": f"Responda em portugu√™s. Use um tom {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('portuguese', {}).get('tone', 'amig√°vel')}.",
        "italian": f"Rispondi in italiano. Usa un tono {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('italian', {}).get('tone', 'amichevole')}.",
        "japanese": f"Êó•Êú¨Ë™û„ÅßËøîÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ{PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('japanese', {}).get('tone', 'Ë¶™„Åó„Åø„ÇÑ„Åô„ÅÑ')}„Éà„Éº„É≥„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "korean": f"ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî. {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('korean', {}).get('tone', 'ÏπúÍ∑ºÌïú')} ÌÜ§ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî.",
        "chinese": f"ËØ∑Áî®‰∏≠ÊñáÂõûÂ§ç„ÄÇ‰ΩøÁî®{PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('chinese', {}).get('tone', 'ÂèãÂ•Ω')}ÁöÑËØ≠Ë∞É„ÄÇ",
        "arabic": f"ÿ£ÿ¨ÿ® ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©. ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÜÿ®ÿ±ÿ© {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('arabic', {}).get('tone', 'ŸàÿØŸäÿ©')}.",
        "hindi": f"‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç‡•§ {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('hindi', {}).get('tone', '‡§Æ‡§ø‡§§‡•ç‡§∞‡§µ‡§§')} ‡§∏‡•ç‡§µ‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§",
        "russian": f"–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ò—Å–ø–æ–ª—å–∑—É–π {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('russian', {}).get('tone', '–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π')} —Ç–æ–Ω.",
        "english": f"Respond in English. Use a {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('english', {}).get('tone', 'friendly')} tone."
    }
    
    # Platform-specific cultural notes
    platform_cultural_notes = {
        "tiktok": {
            "spanish": "Usa jerga juvenil y expresiones como 'qu√© tal', 'genial', 'incre√≠ble'.",
            "french": "Utilise l'argot jeune et des expressions comme 'g√©nial', 'incroyable', 'super'.",
            "german": "Verwende Jugendsprache und Ausdr√ºcke wie 'cool', 'mega', 'krass'.",
            "japanese": "Ëã•ËÄÖË®ÄËëâ„Çí‰Ωø„Å£„Å¶„ÄÅ„Äå„Åô„Åî„ÅÑ„Äç„Äå„ÇÑ„Å∞„ÅÑ„Äç„Äå„Ç®„É¢„ÅÑ„Äç„Å™„Å©„ÅÆË°®Áèæ„Çí‰ΩøÁî®„ÄÇ",
            "korean": "Ï†äÏùÄÏù¥Îì§Ïùò Ïñ∏Ïñ¥Î•º ÏÇ¨Ïö©ÌïòÍ≥† 'ÎåÄÎ∞ï', 'Ï©êÎã§', 'Î©ãÏ†∏' Í∞ôÏùÄ ÌëúÌòÑ ÏÇ¨Ïö©.",
            "chinese": "‰ΩøÁî®Âπ¥ËΩª‰∫∫ÁöÑËØ≠Ë®ÄÔºåÂ¶Ç'Â§™Ê£í‰∫Ü'„ÄÅ'ÂéâÂÆ≥'„ÄÅ'Áâõ'Á≠âË°®Ëææ„ÄÇ",
            "english": "Use Gen Z slang and expressions like 'fire', 'slay', 'no cap'."
        },
        "linkedin": {
            "spanish": "Mant√©n un registro profesional, usa 'usted' si es apropiado.",
            "french": "Maintiens un registre professionnel, utilise 'vous' de mani√®re appropri√©e.",
            "german": "Halte einen professionellen Ton bei, verwende 'Sie' angemessen.",
            "japanese": "Êï¨Ë™û„Çí‰ΩøÁî®„Åó„ÄÅ„Éì„Ç∏„Éç„Çπ„Éû„Éä„Éº„ÇíÂÆà„Å£„Åü‰∏ÅÂØß„Å™Ë°®Áèæ„ÄÇ",
            "korean": "Ï°¥ÎåìÎßêÏùÑ ÏÇ¨Ïö©ÌïòÍ≥† ÎπÑÏ¶àÎãàÏä§ Îß§ÎÑàÎ•º ÏßÄÌÇ® Ï†ïÏ§ëÌïú ÌëúÌòÑ.",
            "chinese": "‰ΩøÁî®Ê≠£ÂºèÂïÜÂä°ËØ≠Ë®ÄÔºå‰øùÊåÅ‰∏ì‰∏öÂíåÂ∞äÈáçÁöÑËØ≠Ë∞É„ÄÇ",
            "english": "Maintain professional language and business etiquette."
        }
    }
    
    base_instruction = language_instructions.get(language, language_instructions["english"])
    cultural_note = platform_cultural_notes.get(platform, {}).get(language, "")
    
    return f"{base_instruction} {cultural_note}".strip()

def get_multilingual_fallback(name: str, platform: str, language: str) -> str:
    """Get platform and language-specific fallback messages"""
    
    first_name = name.split()[0] if name else ""
    lang_data = LANGUAGE_KEYWORDS.get(language, LANGUAGE_KEYWORDS["english"])
    
    greeting = random.choice(lang_data.get("greetings", ["Hi"]))
    connector = random.choice(lang_data.get("connectors", ["I'd love to"]))
    closing = random.choice(lang_data.get("closings", ["Let's connect!"]))
    
    # Platform-specific fallback templates by language
    fallback_templates = {
        "tiktok": {
            "spanish": f"{greeting} {first_name}! {connector} tu contenido. {closing}",
            "french": f"{greeting} {first_name}! {connector} ton contenu. {closing}",
            "german": f"{greeting} {first_name}! {connector} deinen Content. {closing}",
            "portuguese": f"{greeting} {first_name}! {connector} seu conte√∫do. {closing}",
            "japanese": f"{greeting}{first_name}„Åï„ÇìÔºÅ„ÅÇ„Å™„Åü„ÅÆ„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Åå{connector}„ÄÇ{closing}",
            "korean": f"{greeting} {first_name}Îãò! ÎãπÏã†Ïùò ÏΩòÌÖêÏ∏†Î•º {connector}. {closing}",
            "chinese": f"{greeting} {first_name}ÔºÅ{connector}‰Ω†ÁöÑÂÜÖÂÆπ„ÄÇ{closing}",
            "english": f"{greeting} {first_name}! {connector} your content. {closing}"
        },
        "linkedin": {
            "spanish": f"{greeting} {first_name}, {connector} conectar con profesionales como t√∫. {closing}",
            "french": f"{greeting} {first_name}, {connector} me connecter avec des professionnels comme vous. {closing}",
            "german": f"{greeting} {first_name}, {connector} mich mit Fachleuten wie Ihnen zu vernetzen. {closing}",
            "portuguese": f"{greeting} {first_name}, {connector} conectar com profissionais como voc√™. {closing}",
            "japanese": f"{greeting}{first_name}„Åï„Çì„ÄÅ„ÅÇ„Å™„Åü„ÅÆ„Çà„ÅÜ„Å™Â∞ÇÈñÄÂÆ∂„Å®{connector}„ÄÇ{closing}",
            "korean": f"{greeting} {first_name}Îãò, ÎãπÏã† Í∞ôÏùÄ Ï†ÑÎ¨∏Í∞ÄÏôÄ {connector}. {closing}",
            "chinese": f"{greeting} {first_name}Ôºå{connector}‰∏éÂÉèÊÇ®ËøôÊ†∑ÁöÑ‰∏ì‰∏ö‰∫∫Â£´ËÅîÁ≥ª„ÄÇ{closing}",
            "english": f"{greeting} {first_name}, {connector} connect with professionals like you. {closing}"
        }
    }
    
    # Get template for platform and language, fallback to English
    template = fallback_templates.get(platform, fallback_templates.get("linkedin", {}))
    return template.get(language, template.get("english", f"Hi {first_name}! Would love to connect!"))

def detect_user_language(name: str, bio: str, platform_hint: str = None) -> str:
    """Comprehensive language detection from name and bio"""
    
    # Try bio detection first (more reliable)
    bio_language = detect_language_from_bio(bio)
    if bio_language != "english":
        return bio_language
    
    # Try name detection
    name_language = detect_language_from_name(name)
    if name_language != "english":
        return name_language
    
    # Platform-based hints (different platforms are popular in different regions)
    platform_language_hints = {
        "weibo": "chinese",
        "vk": "russian",
        "line": "japanese",
        "kakao": "korean"
    }
    
    if platform_hint and platform_hint.lower() in platform_language_hints:
        return platform_language_hints[platform_hint.lower()]
    
    return "english"

def create_multilingual_dm_prompt(name: str, bio: str, platform: str, persona: str, language: str) -> str:
    """Create a comprehensive multilingual prompt for OpenAI"""
    
    first_name = name.split()[0] if name else "there"
    
    # Base prompt in English (for OpenAI understanding)
    base_prompt = f"""Create a personalized direct message for {first_name} based on their bio: "{bio}". 
This is for {platform} platform using the {persona} persona.

Target language: {language}
Platform: {platform}
Persona: {persona}

Requirements:
1. Write the entire message in {language}
2. Keep it natural and culturally appropriate for {language} speakers
3. Adapt to {platform} platform culture and norms
4. Use the {persona} persona approach
5. Keep it concise and engaging
6. Include appropriate cultural greetings and expressions"""
    
    # Add language and platform specific instructions
    multilingual_modifier = get_multilingual_prompt_modifier(platform, language, persona)
    
    return f"{base_prompt}\n\nSpecific instructions: {multilingual_modifier}"

# Enhanced version of your existing generate_dm_with_fallback function
def generate_multilingual_dm(name: str, bio: str, platform: str, language: str = None, persona: str = None) -> dict:
    """
    Generate multilingual DM - enhanced version of your generate_dm_with_fallback
    
    Returns dict with: dm, language, persona, platform, detected_language
    """
    
    # Auto-detect language if not provided
    if language is None:
        language = detect_user_language(name, bio, platform)
    
    # Import your existing functions (avoiding circular imports)
    try:
        from dm_sequences import match_persona, PERSONAS, initialize_openai_client, generate_dm_with_openai_v1, generate_dm_with_openai_v0
        from personas import PERSONAS as PERSONAS_DATA
    except ImportError:
        # Fallback if imports fail
        print("‚ö†Ô∏è Could not import dm_sequences. Using basic fallback.")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": "fallback",
            "platform": platform,
            "detected_language": language,
            "method": "fallback"
        }
    
    # Get persona (your existing logic)
    if persona is None:
        persona = match_persona(bio)
    
    print(f"üåç Generating {language} DM for {platform} using {persona} persona")
    
    # Create multilingual prompt
    multilingual_prompt = create_multilingual_dm_prompt(name, bio, platform, persona, language)
    
    # Try OpenAI API (your existing logic)
    client, version = initialize_openai_client()
    
    if client is None:
        print("‚ö†Ô∏è OpenAI not available, using multilingual fallback")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "fallback"
        }
    
    try:
        messages = [
            {"role": "system", "content": f"You're a multilingual social media outreach assistant. You can write natural, culturally appropriate DMs in {language} for {platform}."},
            {"role": "user", "content": multilingual_prompt}
        ]
        
        if version == "v1":
            dm_text = generate_dm_with_openai_v1(client, messages)
        elif version == "v0":
            dm_text = generate_dm_with_openai_v0(client, messages)
        else:
            raise Exception("Unknown OpenAI version")
        
        return {
            "dm": dm_text.strip(),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "openai"
        }
            
    except Exception as e:
        print(f"‚ö†Ô∏è OpenAI error: {e}")
        print(f"   Using multilingual fallback for {language}")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "fallback",
            "error": str(e)
        }

def generate_multilingual_batch(contacts: List[Dict], platform: str = "twitter", target_language: str = None) -> List[Dict]:
    """
    Generate multilingual DMs for multiple contacts
    
    Args:
        contacts: List of dicts with 'name' and 'bio' keys
        platform: Target platform
        target_language: Force specific language (None for auto-detection)
    """
    
    results = []
    
    print(f"üåç Generating multilingual DMs for {platform}...")
    
    for contact in contacts:
        try:
            result = generate_multilingual_dm(
                name=contact.get("name", ""),
                bio=contact.get("bio", ""),
                platform=platform,
                language=target_language
            )
            
            # Add original contact info
            result.update({
                "original_name": contact.get("name"),
                "original_bio": contact.get("bio"),
                "length": len(result["dm"])
            })
            
            results.append(result)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error generating multilingual DM for {contact.get('name')}: {e}")
            results.append({
                "original_name": contact.get("name"),
                "original_bio": contact.get("bio"),
                "dm": get_multilingual_fallback(contact.get("name", ""), platform, target_language or "english"),
                "language": target_language or "english",
                "persona": "error",
                "platform": platform,
                "detected_language": "unknown",
                "method": "error_fallback",
                "error": str(e),
                "length": 0
            })
    
    return results

def test_multilingual_generation():
    """Test multilingual DM generation"""
    
    print("üåç Testing Multilingual DM Generation")
    print("=" * 50)
    
    # Test contacts with different languages
    test_contacts = [
        {"name": "Jos√© Garc√≠a", "bio": "Entrenador de fitness que ayuda a personas a alcanzar sus metas de salud"},
        {"name": "Marie Dubois", "bio": "Cr√©atrice de contenu beaut√© sur YouTube avec des tutoriels maquillage"},
        {"name": "Hans Mueller", "bio": "Software-Entwickler mit Leidenschaft f√ºr k√ºnstliche Intelligenz"},
        {"name": "Jo√£o Silva", "bio": "Criador de conte√∫do tech no TikTok, cobrindo gadgets e inova√ß√µes"},
        {"name": "Marco Rossi", "bio": "Imprenditore digitale e consulente marketing per startup"},
        {"name": "Áî∞‰∏≠Â§™ÈÉé", "bio": "„Ç≤„Éº„É†ÂÆüÊ≥ÅËÄÖ„ÅßTwitch„Åß„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈÖç‰ø°„Çí„Åó„Å¶„ÅÑ„Åæ„Åô"},
        {"name": "ÍπÄÎØºÏàò", "bio": "Ïú†ÌäúÎ∏åÏóêÏÑú ÏöîÎ¶¨ ÏΩòÌÖêÏ∏†Î•º ÎßåÎìúÎäî ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ÏûÖÎãàÎã§"},
        {"name": "ÁéãÂ∞èÊòé", "bio": "ÁßëÊäÄÂçö‰∏ªÔºå‰∏ìÊ≥®‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†ÂÜÖÂÆπÂàõ‰Ωú"},
        {"name": "Ahmed Hassan", "bio": "ŸÖÿ∑Ÿàÿ± ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸàŸÖŸáÿ™ŸÖ ÿ®ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ÿßŸÑÿ≠ÿØŸäÿ´ÿ©"},
        {"name": "Ravi Kumar", "bio": "‡§´‡§ø‡§ü‡§®‡•á‡§∏ ‡§ü‡•ç‡§∞‡•á‡§®‡§∞ ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞"},
        {"name": "Ivan Petrov", "bio": "–°–æ–∑–¥–∞—Ç–µ–ª—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö –∏ –±–ª–æ–∫—á–µ–π–Ω —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö"}
    ]
    
    platforms = ["twitter", "tiktok", "linkedin"]
    
    for platform in platforms:
        print(f"\nüì± Testing {platform.upper()}:")
        print("-" * 40)
        
        # Test first 3 contacts for each platform
        results = generate_multilingual_batch(test_contacts[:3], platform)
        
        for result in results:
            print(f"üë§ {result['original_name']} ({result['detected_language']}):")
            print(f"üí¨ {result['dm']}")
            print(f"üé≠ Persona: {result['persona']} | Method: {result['method']}")
            print()

if __name__ == "__main__":
    test_multilingual_generation()
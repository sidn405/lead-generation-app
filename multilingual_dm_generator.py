#!/usr/bin/env python3
"""
Multilingual DM Generation System
Integrates with your existing dm_sequences.py and persona system
"""

import re
import random
from typing import Dict, List, Optional, Tuple

# Language detection keywords and patterns
LANGUAGE_KEYWORDS = {
    "english": {
        "keywords": ["the", "and", "is", "in", "to", "of", "it", "you", "that", "he", "was", "for", "on", "are", "as", "with", "his", "they", "at"],
        "greetings": ["Hi", "Hello", "Hey", "Greetings"],
        "connectors": ["I love", "I'm interested in", "I think it's great", "I'd love to"],
        "closings": ["Let's connect!", "Let's chat!", "Best regards!", "Talk soon!"]
    },
        "spanish": {
        "keywords": ["que", "con", "para", "por", "una", "como", "muy", "todo", "mÃ¡s", "hacer", "tiempo", "trabajo", "vida", "amor", "familia"],
        "greetings": ["Â¡Hola", "Hola", "Â¡Hey", "Saludos"],
        "connectors": ["Me encanta", "Me gusta", "Estoy interesado en", "SerÃ­a genial"],
        "closings": ["Â¡Conectemos!", "Â¡Hablemos!", "Â¡Saludos!", "Â¡Hasta pronto!"]
    },
    "french": {
        "keywords": ["que", "avec", "pour", "dans", "une", "comme", "trÃ¨s", "tout", "plus", "faire", "temps", "travail", "vie", "amour"],
        "greetings": ["Salut", "Bonjour", "Hey", "Coucou"],
        "connectors": ["J'adore", "J'aime", "Je suis intÃ©ressÃ© par", "Ce serait gÃ©nial"],
        "closings": ["Connectons-nous!", "Parlons!", "Ã€ bientÃ´t!", "Salutations!"]
    },
    "german": {
        "keywords": ["und", "mit", "fÃ¼r", "auf", "eine", "wie", "sehr", "alle", "mehr", "machen", "zeit", "arbeit", "leben", "liebe"],
        "greetings": ["Hallo", "Hi", "Hey", "GrÃ¼ÃŸ dich"],
        "connectors": ["Ich liebe", "Mir gefÃ¤llt", "Ich interessiere mich fÃ¼r", "Das wÃ¤re toll"],
        "closings": ["Lass uns connecten!", "Lass uns sprechen!", "Bis bald!", "GrÃ¼ÃŸe!"]
    },
    "portuguese": {
        "keywords": ["que", "com", "para", "por", "uma", "como", "muito", "todo", "mais", "fazer", "tempo", "trabalho", "vida", "amor"],
        "greetings": ["Oi", "OlÃ¡", "E aÃ­", "Opa"],
        "connectors": ["Eu amo", "Eu gosto", "Estou interessado em", "Seria Ã³timo"],
        "closings": ["Vamos nos conectar!", "Vamos conversar!", "AtÃ© logo!", "AbraÃ§os!"]
    },
    "italian": {
        "keywords": ["che", "con", "per", "una", "come", "molto", "tutto", "piÃ¹", "fare", "tempo", "lavoro", "vita", "amore"],
        "greetings": ["Ciao", "Salve", "Ehi", "Buongiorno"],
        "connectors": ["Amo", "Mi piace", "Sono interessato a", "Sarebbe fantastico"],
        "closings": ["Connettiamoci!", "Parliamo!", "A presto!", "Saluti!"]
    },
    "japanese": {
        "keywords": ["ã§ã™", "ã¾ã™", "ã“ã¨", "ã‚‚ã®", "ãŸã‚", "ã«ã¤ã„ã¦", "ã‹ã‚‰", "ã¾ã§", "ã¨ã„ã†", "ã¨ã—ã¦"],
        "greetings": ["ã“ã‚“ã«ã¡ã¯", "ã¯ã˜ã‚ã¾ã—ã¦", "ãŠç–²ã‚Œæ§˜", "ã‚ˆã‚ã—ã"],
        "connectors": ["å¤§å¥½ãã§ã™", "èˆˆå‘³ãŒã‚ã‚Šã¾ã™", "ç´ æ™´ã‚‰ã—ã„ã¨æ€ã„ã¾ã™", "ãœã²"],
        "closings": ["ã¤ãªãŒã‚Šã¾ã—ã‚‡ã†ï¼", "ãŠè©±ã—ã—ã¾ã—ã‚‡ã†ï¼", "ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼", "ã¾ãŸä»Šåº¦ï¼"]
    },
    "korean": {
        "keywords": ["ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ì™€", "ê³¼", "ë¡œ", "ìœ¼ë¡œ", "ì˜", "ë„", "ë§Œ", "ë¶€í„°"],
        "greetings": ["ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ì²˜ìŒ ëµ™ê² ìŠµë‹ˆë‹¤"],
        "connectors": ["ì¢‹ì•„í•©ë‹ˆë‹¤", "ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤", "í›Œë¥­í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤", "ê¼­"],
        "closings": ["ì—°ê²°í•´ìš”!", "ëŒ€í™”í•´ìš”!", "ê°ì‚¬í•©ë‹ˆë‹¤!", "ë˜ ë§Œë‚˜ìš”!"]
    },
    "chinese": {
        "keywords": ["çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸ª", "ä¼š", "è¯´"],
        "greetings": ["ä½ å¥½", "æ‚¨å¥½", "å—¨", "å¤§å®¶å¥½"],
        "connectors": ["æˆ‘å–œæ¬¢", "æˆ‘å¯¹...æ„Ÿå…´è¶£", "æˆ‘è§‰å¾—å¾ˆæ£’", "å¾ˆæƒ³"],
        "closings": ["è®©æˆ‘ä»¬è¿æ¥å§ï¼", "è®©æˆ‘ä»¬èŠèŠï¼", "æœŸå¾…äº¤æµï¼", "å†è§ï¼"]
    },
    "arabic": {
        "keywords": ["ÙÙŠ", "Ù…Ù†", "Ø¥Ù„Ù‰", "Ø¹Ù„Ù‰", "Ù…Ø¹", "Ø¹Ù†", "Ø£Ù†", "ÙƒÙ„", "Ù‡Ø°Ø§", "Ù‡Ø°Ù‡", "Ø§Ù„ØªÙŠ", "Ø§Ù„Ø°ÙŠ", "Ù„ÙƒÙ†", "Ø£Ùˆ"],
        "greetings": ["Ù…Ø±Ø­Ø¨Ø§", "Ø£Ù‡Ù„Ø§", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§"],
        "connectors": ["Ø£Ø­Ø¨", "Ø£Ù‡ØªÙ… Ø¨Ù€", "Ø£Ø¹ØªÙ‚Ø¯ Ø£Ù†Ù‡ Ø±Ø§Ø¦Ø¹", "Ø£ÙˆØ¯"],
        "closings": ["Ù„Ù†ØªÙˆØ§ØµÙ„!", "Ù„Ù†ØªØ­Ø¯Ø«!", "Ù…Ø¹ Ø§Ù„ØªØ­ÙŠØ©!", "Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡!"]
    },
    "hindi": {
        "keywords": ["à¤•à¤¾", "à¤•à¥‡", "à¤•à¥€", "à¤®à¥‡à¤‚", "à¤¸à¥‡", "à¤•à¥‹", "à¤ªà¤°", "à¤”à¤°", "à¤¹à¥ˆ", "à¤¹à¥ˆà¤‚", "à¤¥à¤¾", "à¤¥à¥€", "à¤¹à¥‹à¤—à¤¾", "à¤¹à¥‹à¤—à¥€"],
        "greetings": ["à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤¹à¥ˆà¤²à¥‹", "à¤¹à¤¾à¤¯", "à¤†à¤¦à¤¾à¤¬"],
        "connectors": ["à¤®à¥à¤à¥‡ à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆ", "à¤®à¥ˆà¤‚ à¤°à¥à¤šà¤¿ à¤°à¤–à¤¤à¤¾ à¤¹à¥‚à¤‚", "à¤®à¥à¤à¥‡ à¤²à¤—à¤¤à¤¾ à¤¹à¥ˆ à¤¯à¤¹ à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾ à¤¹à¥ˆ", "à¤®à¥ˆà¤‚ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾"],
        "closings": ["à¤†à¤‡à¤ à¤œà¥à¤¡à¤¼à¤¤à¥‡ à¤¹à¥ˆà¤‚!", "à¤†à¤‡à¤ à¤¬à¤¾à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚!", "à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦!", "à¤«à¤¿à¤° à¤®à¤¿à¤²à¤¤à¥‡ à¤¹à¥ˆà¤‚!"]
    },
    "russian": {
        "keywords": ["Ğ²", "Ğ½Ğ°", "Ñ", "Ğ¿Ğ¾", "Ğ´Ğ»Ñ", "Ğ¾Ñ‚", "Ğ´Ğ¾", "Ğ¸Ğ·", "Ğº", "Ñƒ", "Ğ¾", "Ğ¿Ñ€Ğ¸", "Ğ·Ğ°", "Ğ¿Ğ¾Ğ´"],
        "greetings": ["ĞŸÑ€Ğ¸Ğ²ĞµÑ‚", "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ", "Ğ¥Ğ°Ğ¹", "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑ"],
        "connectors": ["ĞœĞ½Ğµ Ğ½Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑÑ", "ĞœĞµĞ½Ñ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑƒĞµÑ‚", "Ğ¯ Ğ´ÑƒĞ¼Ğ°Ñ, ÑÑ‚Ğ¾ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾", "Ğ¥Ğ¾Ñ‚ĞµĞ»Ğ¾ÑÑŒ Ğ±Ñ‹"],
        "closings": ["Ğ”Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ğ¼ÑÑ!", "Ğ”Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ¼!", "Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!", "Ğ£Ğ´Ğ°Ñ‡Ğ¸!"]
    }
}

# Platform-specific cultural adaptations by language
PLATFORM_LANGUAGE_STYLES = {
    "tiktok": {
        "spanish": {"style": "muy casual", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "juvenil y divertido"},
        "french": {"style": "dÃ©contractÃ©", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "jeune et amusant"},
        "german": {"style": "locker", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "jung und spaÃŸig"},
        "portuguese": {"style": "bem casual", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "jovem e divertido"},
        "japanese": {"style": "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "è‹¥ã€…ã—ãã¦æ¥½ã—ã„"},
        "korean": {"style": "ìºì£¼ì–¼", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "ì Šê³  ì¬ë¯¸ìˆëŠ”"},
        "chinese": {"style": "å¾ˆéšæ„", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "å¹´è½»æœ‰è¶£"},
        "english": {"style": "ultra-casual", "emojis": "ğŸ”¥âœ¨ğŸ’«ğŸš€", "tone": "young and fun"}
    },
    "linkedin": {
        "spanish": {"style": "profesional", "emojis": "", "tone": "respetuoso y profesional"},
        "french": {"style": "professionnel", "emojis": "", "tone": "respectueux et professionnel"},
        "german": {"style": "professionell", "emojis": "", "tone": "respektvoll und professionell"},
        "portuguese": {"style": "profissional", "emojis": "", "tone": "respeitoso e profissional"},
        "japanese": {"style": "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«", "emojis": "", "tone": "æ•¬èªã§ä¸å¯§"},
        "korean": {"style": "ì „ë¬¸ì ", "emojis": "", "tone": "ì •ì¤‘í•˜ê³  ì „ë¬¸ì "},
        "chinese": {"style": "ä¸“ä¸š", "emojis": "", "tone": "å°Šé‡å’Œä¸“ä¸š"},
        "english": {"style": "professional", "emojis": "", "tone": "respectful and professional"}
    }
}

def detect_language_from_bio(bio: str) -> str:
    """Detect language from bio text using keyword matching"""
    if not bio:
        return "english"
    
    bio_lower = bio.lower()
    language_scores = {}
    
    # Score each language based on keyword matches
    for language, data in LANGUAGE_KEYWORDS.items():
        score = 0
        for keyword in data["keywords"]:
            if keyword in bio_lower:
                score += 1
        
        if score > 0:
            language_scores[language] = score
    
    # Return language with highest score, or English as default
    if language_scores:
        detected = max(language_scores, key=language_scores.get)
        print(f"ğŸŒ Detected language: {detected} (score: {language_scores[detected]})")
        return detected
    
    return "english"

def detect_language_from_name(name: str) -> str:
    """Detect language from name patterns (basic heuristics)"""
    if not name:
        return "english"
    
    name_lower = name.lower()
    
    # Simple pattern matching for names
    patterns = {
        "spanish": ["josÃ©", "marÃ­a", "carlos", "ana", "luis", "carmen", "antonio", "francisco"],
        "french": ["pierre", "marie", "jean", "claire", "michel", "sophie", "laurent", "isabelle"],
        "german": ["hans", "anna", "klaus", "petra", "wolfgang", "sabine", "michael", "andrea"],
        "portuguese": ["joÃ£o", "ana", "carlos", "maria", "pedro", "claudia", "ricardo", "patricia"],
        "italian": ["marco", "giulia", "alessandro", "francesca", "andrea", "elena", "matteo", "chiara"],
        "japanese": ["takeshi", "yuki", "hiroshi", "akiko", "kenji", "mari", "satoshi", "emi"],
        "korean": ["kim", "park", "lee", "jung", "choi", "yoon", "jang", "lim"],
        "chinese": ["wang", "li", "zhang", "liu", "chen", "yang", "huang", "zhao"],
        "arabic": ["ahmed", "fatima", "mohamed", "aisha", "ali", "khadija", "omar", "zainab"],
        "russian": ["ivan", "anna", "dmitri", "elena", "sergei", "maria", "alexander", "olga"]
    }
    
    for language, name_patterns in patterns.items():
        for pattern in name_patterns:
            if pattern in name_lower:
                return language
    
    return "english"

def get_multilingual_prompt_modifier(platform: str, language: str, persona: str) -> str:
    """Get language and platform-specific prompt instructions for OpenAI"""
    
    # Base language instructions
    language_instructions = {
        "spanish": f"Responde en espaÃ±ol. Usa un tono {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('spanish', {}).get('tone', 'amigable')}.",
        "french": f"RÃ©ponds en franÃ§ais. Utilise un ton {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('french', {}).get('tone', 'amical')}.",
        "german": f"Antworte auf Deutsch. Verwende einen {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('german', {}).get('tone', 'freundlichen')} Ton.",
        "portuguese": f"Responda em portuguÃªs. Use um tom {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('portuguese', {}).get('tone', 'amigÃ¡vel')}.",
        "italian": f"Rispondi in italiano. Usa un tono {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('italian', {}).get('tone', 'amichevole')}.",
        "japanese": f"æ—¥æœ¬èªã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚{PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('japanese', {}).get('tone', 'è¦ªã—ã¿ã‚„ã™ã„')}ãƒˆãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚",
        "korean": f"í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('korean', {}).get('tone', 'ì¹œê·¼í•œ')} í†¤ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
        "chinese": f"è¯·ç”¨ä¸­æ–‡å›å¤ã€‚ä½¿ç”¨{PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('chinese', {}).get('tone', 'å‹å¥½')}çš„è¯­è°ƒã€‚",
        "arabic": f"Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ø³ØªØ®Ø¯Ù… Ù†Ø¨Ø±Ø© {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('arabic', {}).get('tone', 'ÙˆØ¯ÙŠØ©')}.",
        "hindi": f"à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤œà¤µà¤¾à¤¬ à¤¦à¥‡à¤‚à¥¤ {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('hindi', {}).get('tone', 'à¤®à¤¿à¤¤à¥à¤°à¤µà¤¤')} à¤¸à¥à¤µà¤° à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚à¥¤",
        "russian": f"ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('russian', {}).get('tone', 'Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹')} Ñ‚Ğ¾Ğ½.",
        "english": f"Respond in English. Use a {PLATFORM_LANGUAGE_STYLES.get(platform, {}).get('english', {}).get('tone', 'friendly')} tone."
    }
    
    # Platform-specific cultural notes
    platform_cultural_notes = {
        "tiktok": {
            "spanish": "Usa jerga juvenil y expresiones como 'quÃ© tal', 'genial', 'increÃ­ble'.",
            "french": "Utilise l'argot jeune et des expressions comme 'gÃ©nial', 'incroyable', 'super'.",
            "german": "Verwende Jugendsprache und AusdrÃ¼cke wie 'cool', 'mega', 'krass'.",
            "japanese": "è‹¥è€…è¨€è‘‰ã‚’ä½¿ã£ã¦ã€ã€Œã™ã”ã„ã€ã€Œã‚„ã°ã„ã€ã€Œã‚¨ãƒ¢ã„ã€ãªã©ã®è¡¨ç¾ã‚’ä½¿ç”¨ã€‚",
            "korean": "ì Šì€ì´ë“¤ì˜ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ê³  'ëŒ€ë°•', 'ì©ë‹¤', 'ë©‹ì ¸' ê°™ì€ í‘œí˜„ ì‚¬ìš©.",
            "chinese": "ä½¿ç”¨å¹´è½»äººçš„è¯­è¨€ï¼Œå¦‚'å¤ªæ£’äº†'ã€'å‰å®³'ã€'ç‰›'ç­‰è¡¨è¾¾ã€‚",
            "english": "Use Gen Z slang and expressions like 'fire', 'slay', 'no cap'."
        },
        "linkedin": {
            "spanish": "MantÃ©n un registro profesional, usa 'usted' si es apropiado.",
            "french": "Maintiens un registre professionnel, utilise 'vous' de maniÃ¨re appropriÃ©e.",
            "german": "Halte einen professionellen Ton bei, verwende 'Sie' angemessen.",
            "japanese": "æ•¬èªã‚’ä½¿ç”¨ã—ã€ãƒ“ã‚¸ãƒã‚¹ãƒãƒŠãƒ¼ã‚’å®ˆã£ãŸä¸å¯§ãªè¡¨ç¾ã€‚",
            "korean": "ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ë§¤ë„ˆë¥¼ ì§€í‚¨ ì •ì¤‘í•œ í‘œí˜„.",
            "chinese": "ä½¿ç”¨æ­£å¼å•†åŠ¡è¯­è¨€ï¼Œä¿æŒä¸“ä¸šå’Œå°Šé‡çš„è¯­è°ƒã€‚",
            "english": "Maintain professional language and business etiquette."
        }
    }
    
    base_instruction = language_instructions.get(language, language_instructions["english"])
    cultural_note = platform_cultural_notes.get(platform, {}).get(language, "")
    
    return f"{base_instruction} {cultural_note}".strip()

def get_multilingual_fallback(name: str, platform: str, language: str) -> str:
    """Get platform and language-specific fallback messages"""
    
    first_name = name.split()[0] if name else ""
    lang_data = LANGUAGE_KEYWORDS.get(language, LANGUAGE_KEYWORDS["english"])
    
    greeting = random.choice(lang_data.get("greetings", ["Hi"]))
    connector = random.choice(lang_data.get("connectors", ["I'd love to"]))
    closing = random.choice(lang_data.get("closings", ["Let's connect!"]))
    
    # Platform-specific fallback templates by language
    fallback_templates = {
        "tiktok": {
            "spanish": f"{greeting} {first_name}! {connector} tu contenido. {closing}",
            "french": f"{greeting} {first_name}! {connector} ton contenu. {closing}",
            "german": f"{greeting} {first_name}! {connector} deinen Content. {closing}",
            "portuguese": f"{greeting} {first_name}! {connector} seu conteÃºdo. {closing}",
            "japanese": f"{greeting}{first_name}ã•ã‚“ï¼ã‚ãªãŸã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒ{connector}ã€‚{closing}",
            "korean": f"{greeting} {first_name}ë‹˜! ë‹¹ì‹ ì˜ ì½˜í…ì¸ ë¥¼ {connector}. {closing}",
            "chinese": f"{greeting} {first_name}ï¼{connector}ä½ çš„å†…å®¹ã€‚{closing}",
            "english": f"{greeting} {first_name}! {connector} your content. {closing}"
        },
        "linkedin": {
            "spanish": f"{greeting} {first_name}, {connector} conectar con profesionales como tÃº. {closing}",
            "french": f"{greeting} {first_name}, {connector} me connecter avec des professionnels comme vous. {closing}",
            "german": f"{greeting} {first_name}, {connector} mich mit Fachleuten wie Ihnen zu vernetzen. {closing}",
            "portuguese": f"{greeting} {first_name}, {connector} conectar com profissionais como vocÃª. {closing}",
            "japanese": f"{greeting}{first_name}ã•ã‚“ã€ã‚ãªãŸã®ã‚ˆã†ãªå°‚é–€å®¶ã¨{connector}ã€‚{closing}",
            "korean": f"{greeting} {first_name}ë‹˜, ë‹¹ì‹  ê°™ì€ ì „ë¬¸ê°€ì™€ {connector}. {closing}",
            "chinese": f"{greeting} {first_name}ï¼Œ{connector}ä¸åƒæ‚¨è¿™æ ·çš„ä¸“ä¸šäººå£«è”ç³»ã€‚{closing}",
            "english": f"{greeting} {first_name}, {connector} connect with professionals like you. {closing}"
        }
    }
    
    # Get template for platform and language, fallback to English
    template = fallback_templates.get(platform, fallback_templates.get("linkedin", {}))
    return template.get(language, template.get("english", f"Hi {first_name}! Would love to connect!"))

def detect_user_language(name: str, bio: str, platform_hint: str = None) -> str:
    """Comprehensive language detection from name and bio"""
    
    # Try bio detection first (more reliable)
    bio_language = detect_language_from_bio(bio)
    if bio_language != "english":
        return bio_language
    
    # Try name detection
    name_language = detect_language_from_name(name)
    if name_language != "english":
        return name_language
    
    # Platform-based hints (different platforms are popular in different regions)
    platform_language_hints = {
        "weibo": "chinese",
        "vk": "russian",
        "line": "japanese",
        "kakao": "korean"
    }
    
    if platform_hint and platform_hint.lower() in platform_language_hints:
        return platform_language_hints[platform_hint.lower()]
    
    return "english"

def create_multilingual_dm_prompt(name: str, bio: str, platform: str, persona: str, language: str) -> str:
    """Create a comprehensive multilingual prompt for OpenAI"""
    
    first_name = name.split()[0] if name else "there"
    
    # Base prompt in English (for OpenAI understanding)
    base_prompt = f"""Create a personalized direct message for {first_name} based on their bio: "{bio}". 
This is for {platform} platform using the {persona} persona.

Target language: {language}
Platform: {platform}
Persona: {persona}

Requirements:
1. Write the entire message in {language}
2. Keep it natural and culturally appropriate for {language} speakers
3. Adapt to {platform} platform culture and norms
4. Use the {persona} persona approach
5. Keep it concise and engaging
6. Include appropriate cultural greetings and expressions"""
    
    # Add language and platform specific instructions
    multilingual_modifier = get_multilingual_prompt_modifier(platform, language, persona)
    
    return f"{base_prompt}\n\nSpecific instructions: {multilingual_modifier}"

# Enhanced version of your existing generate_dm_with_fallback function
def generate_multilingual_dm(name: str, bio: str, platform: str, language: str = None, persona: str = None) -> dict:
    """
    Generate multilingual DM - enhanced version of your generate_dm_with_fallback
    
    Returns dict with: dm, language, persona, platform, detected_language
    """
    
    # Auto-detect language if not provided
    if language is None:
        language = detect_user_language(name, bio, platform)
    
    # Import your existing functions (avoiding circular imports)
    try:
        from dm_sequences import match_persona, PERSONAS, initialize_openai_client, generate_dm_with_openai_v1, generate_dm_with_openai_v0
        from personas import PERSONAS as PERSONAS_DATA
    except ImportError:
        # Fallback if imports fail
        print("âš ï¸ Could not import dm_sequences. Using basic fallback.")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": "fallback",
            "platform": platform,
            "detected_language": language,
            "method": "fallback"
        }
    
    # Get persona (your existing logic)
    if persona is None:
        persona = match_persona(bio)
    
    print(f"ğŸŒ Generating {language} DM for {platform} using {persona} persona")
    
    # Create multilingual prompt
    multilingual_prompt = create_multilingual_dm_prompt(name, bio, platform, persona, language)
    
    # Try OpenAI API (your existing logic)
    client, version = initialize_openai_client()
    
    if client is None:
        print("âš ï¸ OpenAI not available, using multilingual fallback")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "fallback"
        }
    
    try:
        messages = [
            {"role": "system", "content": f"You're a multilingual social media outreach assistant. You can write natural, culturally appropriate DMs in {language} for {platform}."},
            {"role": "user", "content": multilingual_prompt}
        ]
        
        if version == "v1":
            dm_text = generate_dm_with_openai_v1(client, messages)
        elif version == "v0":
            dm_text = generate_dm_with_openai_v0(client, messages)
        else:
            raise Exception("Unknown OpenAI version")
        
        return {
            "dm": dm_text.strip(),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "openai"
        }
            
    except Exception as e:
        print(f"âš ï¸ OpenAI error: {e}")
        print(f"   Using multilingual fallback for {language}")
        return {
            "dm": get_multilingual_fallback(name, platform, language),
            "language": language,
            "persona": persona,
            "platform": platform,
            "detected_language": language,
            "method": "fallback",
            "error": str(e)
        }

def generate_multilingual_batch(contacts: List[Dict], platform: str = "twitter", target_language: str = None) -> List[Dict]:
    """
    Generate multilingual DMs for multiple contacts
    
    Args:
        contacts: List of dicts with 'name' and 'bio' keys
        platform: Target platform
        target_language: Force specific language (None for auto-detection)
    """
    
    results = []
    
    print(f"ğŸŒ Generating multilingual DMs for {platform}...")
    
    for contact in contacts:
        try:
            result = generate_multilingual_dm(
                name=contact.get("name", ""),
                bio=contact.get("bio", ""),
                platform=platform,
                language=target_language
            )
            
            # Add original contact info
            result.update({
                "original_name": contact.get("name"),
                "original_bio": contact.get("bio"),
                "length": len(result["dm"])
            })
            
            results.append(result)
            
        except Exception as e:
            print(f"âš ï¸ Error generating multilingual DM for {contact.get('name')}: {e}")
            results.append({
                "original_name": contact.get("name"),
                "original_bio": contact.get("bio"),
                "dm": get_multilingual_fallback(contact.get("name", ""), platform, target_language or "english"),
                "language": target_language or "english",
                "persona": "error",
                "platform": platform,
                "detected_language": "unknown",
                "method": "error_fallback",
                "error": str(e),
                "length": 0
            })
    
    return results

def test_multilingual_generation():
    """Test multilingual DM generation"""
    
    print("ğŸŒ Testing Multilingual DM Generation")
    print("=" * 50)
    
    # Test contacts with different languages
    test_contacts = [
        {"name": "JosÃ© GarcÃ­a", "bio": "Entrenador de fitness que ayuda a personas a alcanzar sus metas de salud"},
        {"name": "Marie Dubois", "bio": "CrÃ©atrice de contenu beautÃ© sur YouTube avec des tutoriels maquillage"},
        {"name": "Hans Mueller", "bio": "Software-Entwickler mit Leidenschaft fÃ¼r kÃ¼nstliche Intelligenz"},
        {"name": "JoÃ£o Silva", "bio": "Criador de conteÃºdo tech no TikTok, cobrindo gadgets e inovaÃ§Ãµes"},
        {"name": "Marco Rossi", "bio": "Imprenditore digitale e consulente marketing per startup"},
        {"name": "ç”°ä¸­å¤ªéƒ", "bio": "ã‚²ãƒ¼ãƒ å®Ÿæ³è€…ã§Twitchã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡ã‚’ã—ã¦ã„ã¾ã™"},
        {"name": "ê¹€ë¯¼ìˆ˜", "bio": "ìœ íŠœë¸Œì—ì„œ ìš”ë¦¬ ì½˜í…ì¸ ë¥¼ ë§Œë“œëŠ” í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤"},
        {"name": "ç‹å°æ˜", "bio": "ç§‘æŠ€åšä¸»ï¼Œä¸“æ³¨äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ å†…å®¹åˆ›ä½œ"},
        {"name": "Ahmed Hassan", "bio": "Ù…Ø·ÙˆØ± ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆÙ…Ù‡ØªÙ… Ø¨Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©"},
        {"name": "Ravi Kumar", "bio": "à¤«à¤¿à¤Ÿà¤¨à¥‡à¤¸ à¤Ÿà¥à¤°à¥‡à¤¨à¤° à¤”à¤° à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¸à¤²à¤¾à¤¹à¤•à¤¾à¤°"},
        {"name": "Ivan Petrov", "bio": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ĞµĞ»ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¾ ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ²Ğ°Ğ»ÑÑ‚Ğ°Ñ… Ğ¸ Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸ÑÑ…"}
    ]
    
    platforms = ["twitter", "tiktok", "linkedin"]
    
    for platform in platforms:
        print(f"\nğŸ“± Testing {platform.upper()}:")
        print("-" * 40)
        
        # Test first 3 contacts for each platform
        results = generate_multilingual_batch(test_contacts[:3], platform)
        
        for result in results:
            print(f"ğŸ‘¤ {result['original_name']} ({result['detected_language']}):")
            print(f"ğŸ’¬ {result['dm']}")
            print(f"ğŸ­ Persona: {result['persona']} | Method: {result['method']}")
            print()

if __name__ == "__main__":
    test_multilingual_generation()